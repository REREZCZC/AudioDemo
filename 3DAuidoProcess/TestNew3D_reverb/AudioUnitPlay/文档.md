# Play local audio file via Audio Unit, just a simple Demo.
# .h

    typedef struct { 
    BOOL                  isStereo;
    UInt32                frameCount;
    UInt32                sampleNumber;
    AudioUnitSampleType   *audioDataLeft;
    AudioUnitSampleType   *audioDataRight;
    } soundStruct, *soundStructPtr;
    
    --------			

    Float64                       sampleRate;
    soundStruct                   soundStructInfo;
    AudioUnit                     outputUnit;
    AudioStreamBasicDescription   fileASBD;
    AudioUnitSampleType           allData; //data to process


    - (void)play;
    - (void)stop;
    - (void)pause;
    

# .m
## 一. 读取 Audio file

###`Read to audio object.`

*   URLForResource: withExtension:
*   Instantiate an extended Audio File object.
*   Open an audio file and associate it with the extended audio file object.

### `Get property`

*   get the audio file's length in frame (totalFramesInfile)
*   Get the audio file's number of channels(fileAudioFormat)
*   Set channelCount from fileAudioFormat.mChannelsPerFrame

### `Allocate memory`

*   Allocate memory in the soundStructArray instance variable to hold the left channel.(soundStructInfo.auidoDataLeft)
*   Instance an AudioStreamBasicDescription object,and set property.(importFormat)
*   If stereo ,allocate memory in the soundStructArray instace variable to hold the right channel audio data.
*   fileASBD = importFormat
*   set property "KExtAudioFilePrwoperty_ClientDataFormat" use "ExtAudioFileSetProperty".

### `Write to BufferList`

*   Instantiate an "AuidoBufferList" object.
*   Allocate memory
*   Set up the AudioBuffer structs in the buffer list, (bufferList->mBuffers[0].mData = soundStructInfo.audioDataLeft)if stereo or channelCount = 2,(bufferList->mBuffers[1].mData = soundStructInfo.audioDataRight).
*   Use "ExtAudioFileRead" to read "bufferList".
*   free memory.


## 二. Configure Audio Unit

*   Instantiate an "AudioComponentDescription" object.
*   Set AudioComponentDescription struct.
*   Get component.
*   Get Audio unit.
*   Set Audio unit property.EnableIO/ElementCount/MaximumFramePerSlice/StreamFormat/SampleRate
*   Set output callback:`callbackStruct.input = &inputRenderCallback`,,,`callbackStruct.inputProcRefCon = &soundStructInfo`
*   Initalize AudioUnit.


## 三. Play operation
*   Play
*   pause
*   stop


# Yinman Audio Process

## YinManAudioSDK
#### 这个 Audio Framework提供了将右声道数据清除的方法.
* 头文件 **YinManAudioAPI.h**
* 接口 ymKeepLeftProcess(unsigned int *in, unsigned int *out, unsigned int nSamples, unsigned int nChannels, unsigned int modeEnable, unsigned int interleave);
* unsigned int *in ,输入 buffer
* unsigned int *out,输出 buffer
* unsigned int nSamples, 每次处理数据的大小
* unsigned int nChannels, channels数
* unsigned int modeEnable,
* unsigned int interleave, 音频数据的形式(交叉形式或者其他)

#### YinManAudioSDK 使用
Audio Unit 的 callback 函数处理的是左右两个声道的 buffer(dataInLeft/dataInRight), 首先要将两个 buffer 的数据合成一个 buffer(allData), _代码中61~72行为音频处理过程._

* 创建一个足以能够容纳左右两个 buffer 的 allData,分配好内存
* 将左右两个 buffer 的数据依次拷贝到 allData 中
* 将allData作为 ymKeepLeftProcess函数的输入参数,传到里面,然后用 allData 作为输出用来接收处理后的数据,
* 设置 "nSample" 参数为 callback提供的"inNumberFrame"
* 设置 "nChannels"为"YinManAudioMaxChannelCount"
* 设置 "modeEnable"为 1
* 设置 "interLeave" 为  0(表示音频 buffer 的数据格式不是交叉类型)
* 由于作为播放的 buffer 也是左右两个声道,所以还要讲处理好的数据的前半部分拷贝到 dataInLeft,后半部分拷贝到 dataInRight
* 释放掉刚才分配的内存,
* 最后将处理后得到的左右两个声道的数据,分配赋给 ioData->mBuffer[0] 和ioData->mBuffer[1]进行播放



